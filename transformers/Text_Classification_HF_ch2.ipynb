{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNGsA/O8IKtzN/3tTOx8K0U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waelrash1/llms/blob/main/transformers/Text_Classification_HF_ch2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformers installation\n",
        "! pip install transformers datasets\n",
        "# To install from source instead of the last release, comment the command above and uncomment the following one.\n",
        "# ! pip install git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "id": "6mbK6gwlq6eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jc8Cb9LTq1vN"
      },
      "outputs": [],
      "source": [
        "from datasets import list_datasets\n",
        "all_datasets = list_datasets()\n",
        "print(f\"There are {len(all_datasets)} datasets currently available on the Hub\")\n",
        "print(f\"The first 10 are: {all_datasets[:10]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "emotions = load_dataset(\"emotion\")\n"
      ],
      "metadata": {
        "id": "WJpv4iWWrYdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(emotions)\n",
        "train_ds = emotions[\"train\"]\n",
        "print(train_ds)\n"
      ],
      "metadata": {
        "id": "v5XJPDmprgvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_ds))\n",
        "print(train_ds[0])\n",
        "print(train_ds.features)"
      ],
      "metadata": {
        "id": "nY5_yJizsZBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "emotions.set_format(type=\"pandas\")\n",
        "df = emotions[\"train\"][:]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Z_r6Bop3tgGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_int2str(row):\n",
        "  return emotions[\"train\"].features[\"label\"].int2str(row)\n",
        "\n",
        "df[\"label_name\"] = df[\"label\"].apply(label_int2str)\n",
        "df"
      ],
      "metadata": {
        "id": "R51nbytkuASw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DbouGPVvKl09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import matplotlib.pyplot as plt\n",
        "df[\"label_name\"].value_counts(ascending=True).plot.barh()\n",
        "plt.title(\"Frequency of Classes\")\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "JA6ZUO5Q0osa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Words Per Tweet\"] = df[\"text\"].str.split().apply(len)\n",
        "df.boxplot(\"Words Per Tweet\", by=\"label_name\", grid=False,\n",
        "showfliers=False, color=\"black\")\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4OKiB_6w1zhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "Wttr8us52ztn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"This notebook is open with private outputs. Outputs will not be saved. You can disable this in Notebook settings.\"\n",
        "encoded_text = tokenizer(text)\n",
        "print(encoded_text)\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
        "print(tokens)\n",
        "print(tokenizer.convert_tokens_to_string(tokens))"
      ],
      "metadata": {
        "id": "bBtvHqDQ3RHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "id": "q78fTE-l4JQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.model_max_length"
      ],
      "metadata": {
        "id": "jcKtU66L4QAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "  return tokenizer(batch[\"text\"], padding=True, truncation=True)"
      ],
      "metadata": {
        "id": "tCML0wSR4oWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions.reset_format"
      ],
      "metadata": {
        "id": "rmW0ebYY45In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenize(emotions[\"train\"][:2]))"
      ],
      "metadata": {
        "id": "whDUZCOo4wVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)"
      ],
      "metadata": {
        "id": "zOhP8-YW67PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "import torch\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModel.from_pretrained(model_ckpt).to(device)"
      ],
      "metadata": {
        "id": "t3tfM4957u7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = [[\"this is a test\",\"Hello to the world of transformers.\"]]\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "print(f\"Input tensor shape: {inputs['input_ids'].size()}\")"
      ],
      "metadata": {
        "id": "x57Jr3qP8oC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "id": "Nq7tpg3b6Vsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {k:v.to(device) for k,v in inputs.items()}\n"
      ],
      "metadata": {
        "id": "A0aCcChC8xDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "print(outputs)"
      ],
      "metadata": {
        "id": "buO1OJxq7RE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.last_hidden_state.size()"
      ],
      "metadata": {
        "id": "D2jLle221Rkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.last_hidden_state[:,0]"
      ],
      "metadata": {
        "id": "a5V7s44c_pnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_hidden_states(batch):\n",
        "# Place model inputs on the GPU\n",
        "  inputs = {k:v.to(device) for k,v in batch.items()\n",
        "  if k in tokenizer.model_input_names}\n",
        "# Extract last hidden states\n",
        "  with torch.no_grad():\n",
        "    last_hidden_state = model(**inputs).last_hidden_state\n",
        "# Return vector for [CLS] token\n",
        "  return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}"
      ],
      "metadata": {
        "id": "Fr52iWPvCAHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded.set_format(\"torch\",\n",
        "columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "#We can then go ahead and extract the hidden states across all splits in one go:\n",
        "emotions_hidden = emotions_encoded.map(extract_hidden_states, batched=True)\n",
        "#Notice that we did not set batch_size=None in this case, which means the default\n",
        "#batch_size=1000 is used instead. As expected, applying the extract_ hidden_\n",
        "#states() function has added a new hidden_state column to our dataset:\n",
        "emotions_hidden[\"train\"].column_names"
      ],
      "metadata": {
        "id": "n2Fv_lJ1CehW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded"
      ],
      "metadata": {
        "id": "vUVp0xrwCxtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X_train = np.array(emotions_hidden[\"train\"][\"hidden_state\"])\n",
        "X_valid = np.array(emotions_hidden[\"validation\"][\"hidden_state\"])\n",
        "y_train = np.array(emotions_hidden[\"train\"][\"label\"])\n",
        "y_valid = np.array(emotions_hidden[\"validation\"][\"label\"])\n",
        "X_train.shape, X_valid.shape"
      ],
      "metadata": {
        "id": "Jf3s11aMDnOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn"
      ],
      "metadata": {
        "id": "EiR8-HBKEAS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import umap.umap_ as UMAP\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Scale features to [0,1] range\n",
        "X_scaled = MinMaxScaler().fit_transform(X_train)\n",
        "# Initialize and fit UMAP\n",
        "mapper = UMAP.UMAP(n_components=2, metric=\"cosine\").fit(X_scaled)\n",
        "# Create a DataFrame of 2D embeddings\n",
        "df_emb = pd.DataFrame(mapper.embedding_, columns=[\"X\", \"Y\"])\n",
        "df_emb[\"label\"] = y_train\n",
        "df_emb.head()"
      ],
      "metadata": {
        "id": "BhGjBtbXD4-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(7,5))\n",
        "axes = axes.flatten()\n",
        "cmaps = [\"Greys\", \"Blues\", \"Oranges\", \"Reds\", \"Purples\", \"Greens\"]\n",
        "labels = emotions[\"train\"].features[\"label\"].names\n",
        "for i, (label, cmap) in enumerate(zip(labels, cmaps)):\n",
        "  df_emb_sub = df_emb.query(f\"label == {i}\")\n",
        "  axes[i].hexbin(df_emb_sub[\"X\"], df_emb_sub[\"Y\"], cmap=cmap,\n",
        "  gridsize=20, linewidths=(0,))\n",
        "  axes[i].set_title(label)\n",
        "  axes[i].set_xticks([]), axes[i].set_yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n81ntnGCGh2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "# We increase `max_iter` to guarantee convergence\n",
        "lr_clf = LogisticRegression(max_iter=3000)\n",
        "lr_clf.fit(X_train, y_train)\n",
        "lr_clf.score(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "oMSOC-AcH4hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "dummy_clf.score(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "1KcHcjyvILj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_confusion_matrix(y_preds, y_true, labels):\n",
        "  cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
        "  fig, ax = plt.subplots(figsize=(6, 6))\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "  disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
        "  plt.title(\"Normalized confusion matrix\")\n",
        "  plt.show()\n",
        "\n",
        "labels = emotions[\"train\"].features[\"label\"].names\n",
        "y_preds = lr_clf.predict(X_valid)\n",
        "plot_confusion_matrix(y_preds, y_valid, labels)"
      ],
      "metadata": {
        "id": "fhkuQd0HIfIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading a pretrained model\n",
        "The first thing we need is a pretrained DistilBERT model like the one we used in the\n",
        "feature-based approach. The only slight modification is that we use the AutoModelFor\n",
        "SequenceClassification model instead of AutoModel. The difference is that the\n",
        "AutoModelForSequenceClassification model has a classification head on top of the\n",
        "pretrained model outputs, which can be easily trained with the base model. We just\n",
        "need to specify how many labels the model has to predict (six in our case), since this\n",
        "dictates the number of outputs the classification head has:\n"
      ],
      "metadata": {
        "id": "7JRi_z9qahoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "num_labels = 6\n",
        "model = (AutoModelForSequenceClassification\n",
        ".from_pretrained(model_ckpt, num_labels=num_labels)\n",
        ".to(device))"
      ],
      "metadata": {
        "id": "s9NX-wTZaobU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\"accuracy\": acc, \"f1\": f1}"
      ],
      "metadata": {
        "id": "vCoaryH2cViB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "R-AM3Od3c4uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "XB6F6hHteOU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import accelerate; import transformers; print(transformers.__version__); print(accelerate.__version__)"
      ],
      "metadata": {
        "id": "zj9jbsene9Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "import accelerate\n",
        "batch_size = 32\n",
        "logging_steps = len(emotions_encoded[\"train\"]) // batch_size\n",
        "model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
        "training_args = TrainingArguments(output_dir=model_name,\n",
        "num_train_epochs=4,\n",
        "learning_rate=2e-5,\n",
        "per_device_train_batch_size=batch_size,\n",
        "per_device_eval_batch_size=batch_size,\n",
        "weight_decay=0.01,\n",
        "evaluation_strategy=\"epoch\",\n",
        "disable_tqdm=False,\n",
        "logging_steps=logging_steps,\n",
        "push_to_hub=True,\n",
        "log_level=\"error\")"
      ],
      "metadata": {
        "id": "MvD8_0zdeDKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "trainer = Trainer(model=model, args=training_args,\n",
        "compute_metrics=compute_metrics,\n",
        "train_dataset=emotions_encoded[\"train\"],\n",
        "eval_dataset=emotions_encoded[\"validation\"],\n",
        "tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "id": "LFPENxrcg0wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train();"
      ],
      "metadata": {
        "id": "TZmbjb47hI9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output = trainer.predict(emotions_encoded[\"validation\"])"
      ],
      "metadata": {
        "id": "bbHRLsKpinko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output.metrics"
      ],
      "metadata": {
        "id": "IgihY5P4iqQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_preds = np.argmax(preds_output.predictions, axis=1)"
      ],
      "metadata": {
        "id": "CyIRO79xjEQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = emotions[\"train\"].features[\"label\"].names\n",
        "y_valid = np.array(emotions[\"validation\"][\"label\"])\n",
        "\n",
        "plot_confusion_matrix(y_preds, y_valid, labels)\n"
      ],
      "metadata": {
        "id": "pCPZvJ8_jmSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error analysis\n",
        "Before moving on, we should investigate our model’s predictions a little bit further. A\n",
        "simple yet powerful technique is to sort the validation samples by the model loss.\n",
        "When we pass the label during the forward pass, the loss is automatically calculated\n",
        "and returned. Here’s a function that returns the loss along with the predicted label:"
      ],
      "metadata": {
        "id": "ufHoNA9bmTV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.nn.functional import cross_entropy\n",
        "def forward_pass_with_label(batch):\n",
        "# Place all input tensors on the same device as the model\n",
        "  inputs = {k:v.to(device) for k,v in batch.items()\n",
        "  if k in tokenizer.model_input_names}\n",
        "  with torch.no_grad():\n",
        "    output = model(**inputs)\n",
        "    pred_label = torch.argmax(output.logits, axis=-1)\n",
        "    loss = cross_entropy(output.logits, batch[\"label\"].to(device),\n",
        "    reduction=\"none\")\n",
        "# Place outputs on CPU for compatibility with other dataset columns\n",
        "\n",
        "  return {\"loss\": loss.cpu().numpy(),\n",
        "  \"predicted_label\": pred_label.cpu().numpy()}"
      ],
      "metadata": {
        "id": "quvvg_a5mM-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert our dataset back to PyTorch tensors\n",
        "emotions_encoded.set_format(\"torch\",\n",
        "columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "# Compute loss values\n",
        "emotions_encoded[\"validation\"] = emotions_encoded[\"validation\"].map(\n",
        "forward_pass_with_label, batched=True, batch_size=16)"
      ],
      "metadata": {
        "id": "MTMmYgzJm6g_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded.set_format(\"pandas\")\n",
        "cols = [\"text\", \"label\", \"predicted_label\", \"loss\"]\n",
        "df_test = emotions_encoded[\"validation\"][:][cols]\n",
        "df_test[\"label\"] = df_test[\"label\"].apply(label_int2str)\n",
        "df_test[\"predicted_label\"] = (df_test[\"predicted_label\"]\n",
        ".apply(label_int2str))"
      ],
      "metadata": {
        "id": "3HLfDkcAm_Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.sort_values(\"loss\", ascending=False).head(10)"
      ],
      "metadata": {
        "id": "eSgazmq7pNko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.sort_values(\"loss\", ascending=True).head(10)"
      ],
      "metadata": {
        "id": "vusXwB5aqNp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(commit_message=\"Training completed!\")"
      ],
      "metadata": {
        "id": "rcXXcEDMrYIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "# Change `transformersbook` to your Hub username\n",
        "model_id = \"waelrash1/distilbert-base-uncased-finetuned-emotion\"\n",
        "classifier = pipeline(\"text-classification\", model=model_id)"
      ],
      "metadata": {
        "id": "d3IXyezSrvFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"WaelRash1/distilbert-base-uncased-finetuned-emotion\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"WaelRash1/distilbert-base-uncased-finetuned-emotion\")"
      ],
      "metadata": {
        "id": "-qkkJ4I7sY31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "custom_tweet = \"I saw a movie today and it was really good.\"\n",
        "preds = classifier(custom_tweet, return_all_scores=True)\n",
        "#Finally, we can plot the probability for each class in a bar plot. Clearly, the model estimates\n",
        "#that the most likely class is joy, which appears to be reasonable given the tweet:\n",
        "preds_df = pd.DataFrame(preds[0])\n",
        "plt.bar(labels, 100 * preds_df[\"score\"], color='C0')\n",
        "plt.title(f'\"{custom_tweet}\"')\n",
        "plt.ylabel(\"Class probability (%)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HedjRJTaslB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "id": "1gqlt380s5sm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}